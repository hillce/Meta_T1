{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0c428e58dc82dbe1017e174b4aea0903d12c3fd818f3732ea4cfc62850a0637c7",
   "display_name": "Python 3.7.9 64-bit ('venv')"
  },
  "metadata": {
   "interpreter": {
    "hash": "c428e58dc82dbe1017e174b4aea0903d12c3fd818f3732ea4cfc62850a0637c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Preprocessing and Library loading:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, sys, time, os, copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6.4*2, 4.8*2]\n",
    "sns.set_theme(\"paper\")\n",
    "sns.set_style(style=\"darkgrid\")\n",
    "fullDataset = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Files:  31199\n"
     ]
    }
   ],
   "source": [
    "jsonDir = \"./jsonFiles\"\n",
    "numpyDir = \"./numpyFiles\"\n",
    "\n",
    "fullTestSet = np.load(os.path.join(numpyDir,\"fullTestSet.npy\"))\n",
    "errMSE = np.load(os.path.join(numpyDir,\"ERROR_MAE_3D_T1.npy\"))\n",
    "\n",
    "with open(os.path.join(jsonDir,\"file_list_3D_MAE.json\"),\"r\") as f:\n",
    "    fileList = json.load(f)\n",
    "\n",
    "fileList = [x[:-8] for x in fileList]\n",
    "\n",
    "print(\"Number of Files: \", len(fileList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pre Flatten (31199, 8, 7, 7) vs. Flattened (31199, 392)\n"
     ]
    }
   ],
   "source": [
    "# Flattening Error volume 8x7x7 for RF\n",
    "\n",
    "errFlat = np.zeros((errMSE.shape[0],errMSE.shape[1]*errMSE.shape[2]*errMSE.shape[3]))\n",
    "\n",
    "for i in range(errMSE.shape[0]):\n",
    "    errFlat[i] = errMSE[i,:,:,:].flatten()\n",
    "\n",
    "print(\"Pre Flatten {} vs. Flattened {}\".format(errMSE.shape,errFlat.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in tags and additional meta data:\n",
    "\n",
    "with open(os.path.join(jsonDir,\"./reasons_split.json\"),\"r\") as f: # Tags\n",
    "    tagDict = json.load(f)\n",
    "\n",
    "if not fullDataset:\n",
    "    with open(os.path.join(jsonDir,\"biobank_meta_float.json\"),\"r\") as f: # Float meta data from dcm headers\n",
    "        metaDict = json.load(f)\n",
    "else:\n",
    "    with open(os.path.join(jsonDir,\"biobank_meta_full_one_hot.json\"),\"r\") as f: # All one hot encoded meta\n",
    "        metaDict = json.load(f)\n",
    "\n",
    "with open(os.path.join(jsonDir,\"Biobank_Bounding_Boxes.json\"),\"r\") as f: # Bounding box meta data\n",
    "    bBoxes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Files with complete meta data:  31199\n"
     ]
    }
   ],
   "source": [
    "# Sort through subj to make sure all meta data present\n",
    "\n",
    "if fullDataset:\n",
    "    keys = list(metaDict['eid'].values())\n",
    "else:\n",
    "    keys = list(metaDict.keys())\n",
    "\n",
    "keys = [k for k in keys if k in bBoxes.keys()]\n",
    "keys = [k for k in keys if k in fileList]\n",
    "\n",
    "print(\"Number of Files with complete meta data: \", len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Meta values to use: \n\n ['[SlicePosition_PCS]_0', '[SlicePosition_PCS]_1', '[SlicePosition_PCS]_2', 'Accession Number', 'Echo Train Length', '1', '1_1_0', '2', '3', '4', 'NONE', 'NONE_1_0', 'Algo1', 'WINDOW1', 'Echo Number(s)', 'TI_0', 'TI_1', 'TI_2', 'TI_3', 'TI_4', 'TI_5', 'TI_6', '[TimeAfterStart]_0', '[TimeAfterStart]_1', '[TimeAfterStart]_2', '[TimeAfterStart]_3', '[TimeAfterStart]_4', '[TimeAfterStart]_5', '[TimeAfterStart]_6', 'Samples per Pixel', 'ShMOLLI_192i', 'ShMOLLI_192i LIVER', '[SliceMeasurementDuration]_0', '[SliceMeasurementDuration]_1', '[SliceMeasurementDuration]_2', '[SliceMeasurementDuration]_3', '[SliceMeasurementDuration]_4', '[SliceMeasurementDuration]_5', '[SliceMeasurementDuration]_6', 'Image Position (Patient)_0', 'Image Position (Patient)_1', 'Image Position (Patient)_2', 'Largest Image Pixel Value_0', 'Largest Image Pixel Value_1', 'Largest Image Pixel Value_2', 'Largest Image Pixel Value_3', 'Largest Image Pixel Value_4', 'Largest Image Pixel Value_5', 'Largest Image Pixel Value_6', '288p*384 I', '288p*384s I', '308p*384 I', '312p*384 I', '316p*384 I', '328p*384 I', 'Repetition Time', 'Slice Location', 'Image Orientation (Patient)_0', 'Image Orientation (Patient)_1', 'Image Orientation (Patient)_2', 'Image Orientation (Patient)_3', 'Image Orientation (Patient)_4', 'Image Orientation (Patient)_5', 'Columns', 'Acquisition Time_0', 'Acquisition Time_1', 'Acquisition Time_2', 'Acquisition Time_3', 'Acquisition Time_4', 'Acquisition Time_5', 'Acquisition Time_6', '[CSA Series Header Version]', 'Smallest Image Pixel Value', \"Patient's Age\", 'Pixel Spacing_0', 'Pixel Spacing_1', 'Number of Averages', 'Flip Angle', \"Patient's Birth Date\", 'Pixel Representation', 'Instance Creation Time_0', 'Instance Creation Time_1', 'Instance Creation Time_2', 'Instance Creation Time_3', 'Instance Creation Time_4', 'Instance Creation Time_5', 'Instance Creation Time_6', 'Window Center_0', 'Window Center_1', 'Window Center_2', 'Window Center_3', 'Window Center_4', 'Window Center_5', 'Window Center_6', 'Series Number', 'BO1', 'BO1,2;BO2,3;SP1', 'BO1,2;BO2,3;SP1,2', 'BO1,2;BO2,3;SP1-4', 'BO1,2;BO2,3;SP2', 'BO1,2;BO2,3;SP2,3', 'BO1,2;BO2,3;SP3', 'BO1,2;SP1', 'BO1,2;SP1,2', 'BO1,2;SP2', 'BO1,2;SP2,3', 'BO1,2;SP3', 'BO1,2;SP3,4', 'BO1,2;SP4', 'BO1,2;SP4,5', 'BO1,2;SP7', 'BO1-3;BO2,3;SP1,2', 'BO1-3;BO2,3;SP2', 'BO1-3;BO2,3;SP2,3', 'BO1-3;BO2;SP1,2', 'BO1-3;BO2;SP2', 'BO1-3;BO2;SP2,3', 'BO1-3;SP1,2', 'BO1-3;SP2', 'BO1-3;SP2,3', 'BO1-3;SP2-4', 'BO1;BO1-3;SP1-4', 'BO1;BO2,3;SP1,2', 'BO1;BO2,3;SP1-3', 'BO1;BO2,3;SP2', 'BO1;BO2,3;SP2,3', 'BO1;BO2,3;SP2-4', 'BO1;BO2,3;SP3', 'BO1;BO2,3;SP3,4', 'BO1;BO2,3;SP4', 'BO1;BO2;SP1,2', 'BO1;BO2;SP2', 'BO1;BO2;SP2,3', 'BO1;BO3;SP2,3', 'BO1;BO3;SP3', 'BO1;BO3;SP3,4', 'BO1;BO3;SP4', 'BO1;SP1', 'BO1;SP1,2', 'BO1;SP2', 'BO1;SP2,3', 'BO1;SP3', 'BO2,3;BO1;SP1,2', 'BO2,3;BO1;SP2', 'BO2,3;BO1;SP2,3', 'BO2,3;BO1;SP3', 'BO2,3;BO1;SP3,4', 'BO2,3;BO2,3;SP1,2', 'BO2,3;BO2,3;SP2', 'BO2,3;BO2,3;SP2,3', 'BO2,3;BO2,3;SP3', 'BO2,3;BO2,3;SP3,4', 'BO2,3;BO2,3;SP4', 'BO2,3;SP1', 'BO2,3;SP1,2', 'BO2,3;SP1-3', 'BO2,3;SP2', 'BO2,3;SP2,3', 'BO2,3;SP2-4', 'BO2,3;SP3', 'BO2,3;SP3,4', 'BO2,3;SP4', 'BO2,3;SP4,5', 'BO2,3;SP5', 'BO2;BO1,2;SP2', 'BO2;BO1;SP3', 'BO2;BO2,3;SP1,2', 'BO2;BO2,3;SP2', 'BO2;BO2,3;SP2,3', 'BO2;BO2,3;SP3', 'BO2;BO2,3;SP3,4', 'BO2;BO2;SP2', 'BO2;BO2;SP2,3', 'BO2;BO3;SP1,2', 'BO2;SP1', 'BO2;SP1,2', 'BO2;SP2', 'BO2;SP2,3', 'BO2;SP3', 'BO2;SP3,4', 'BO2;SP4', 'BO2;SP4,5', 'BO3;BO1;SP2', 'BO3;BO1;SP2,3', 'BO3;BO1;SP3', 'BO3;BO1;SP3,4', 'BO3;BO1;SP4', 'BO3;BO1;SP4,5', 'BO3;BO2,3;SP2,3', 'BO3;BO2,3;SP3', 'BO3;BO2,3;SP3,4', 'BO3;BO2,3;SP4', 'BO3;SP1,2', 'BO3;SP2', 'BO3;SP2,3', 'BO3;SP3', 'BO3;SP3,4', 'BO3;SP4', 'BO3;SP4,5', 'BO3;SP6,7', 'SP1', 'SP1,2', 'SP2', 'SP2,3', 'SP3', 'SP3,4', 'Percent Sampling', 'Slice Thickness', 'Number of Phase Encoding Steps', 'Echo Time', 'Inversion Time', 'Bits Stored', 'Window Width_0', 'Window Width_1', 'Window Width_2', 'Window Width_3', 'Window Width_4', 'Window Width_5', 'Window Width_6', 'F', 'M', 'O', 'SAR', 'Device Serial Number', 'Bits Allocated', '[CSA Image Header Version]', '[RealDwellTime]', 'Percent Phase Field of View', '[SliceResolution]', 'Content Time_0', 'Content Time_1', 'Content Time_2', 'Content Time_3', 'Content Time_4', 'Content Time_5', 'Content Time_6', \"Patient's Size\", 'Imaging Frequency', 'Rows', 'UK Biobank Abdomen', 'UK Biobank Abdomen 24.04.2014', 'UK Biobank Archived Protocols^UK Biobank Abdomen', 'UK Biobank UK Biobank Abdomen_Current', 'UK Biobank UK Biobank Abdomen_Currrent', 'UK Biobank abdo', 'UK Biobank abdomen', 'UK Biobank^UK Biobank Abdomen_Current', 'UK Biobank^UK Biobank Abdomen_Currrent', 'UK Biobank^UK Biobank Heart_Auto_Breathhold', 'UK Biobank^UK Biobank Heart_Currrent', 'UK Biobank^abdomen', 'UK Biobank^heart', 'UKBB abdomen', 'UKBB^Heart', 'UKBB^PD29032017', 'UKBB^abdomen', 'UKBB^heart', 'UK_BioBank abdomen', 'UK_Biobank Abdomen', 'UK_Biobank abdo', 'UK_Biobank abdomen', 'UK_Biobank^abdomen', 'UK_Biobank^heart', 'abdomen^Abdomen Dot Engine', 'uk biobank abdomen', 'FFS', 'HFS', 'COL', 'ROW', 'Pixel Bandwidth', 'Acquisition Number', 'High Bit', \"Patient's Weight\", 'Magnetic Field Strength', 'ABDOMEN', 'ABDOMENPELVIS', 'BRAIN', 'HEAD', 'HEART', 'dB/dt', 'tfi2d1_84', 'tfi2d1_89', 'tfi2d1_90', 'tfi2d1_91', 'tfi2d1_94', 'eid']\n"
     ]
    }
   ],
   "source": [
    "###### Find out the keys present in every single case:\n",
    "if not fullDataset:\n",
    "    allMetaKeys = []\n",
    "    instTime = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]\n",
    "    for k in keys:\n",
    "        for i in instTime:\n",
    "            allMetaKeys.extend(list(metaDict[k][i].keys()))\n",
    "\n",
    "    allMetaKeysSet = set(allMetaKeys)\n",
    "\n",
    "    keysOI = []\n",
    "    for k in allMetaKeysSet:\n",
    "        if allMetaKeys.count(k) == (len(keys)*7):\n",
    "            keysOI.append(k)\n",
    "else:\n",
    "    keysOI = list(metaDict.keys())\n",
    "\n",
    "print(\"Meta values to use: \\n\\n\", keysOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[31198/31199]\n",
      " Meta Data for Subj0: [-221.11607361 -140.75375366   -0.25          0.            1.\n",
      "    1.            0.            0.            0.            0.        ] \n",
      " Tag for Subj0: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create dataset (full one hot):\n",
    "if fullDataset:\n",
    "    subjLength = len(keys)\n",
    "    dataLength = len(keysOI)\n",
    "    bBoxesLength = 16\n",
    "    errLength = errFlat.shape[1]\n",
    "\n",
    "    ownDataset = np.zeros((subjLength,dataLength + bBoxesLength + errLength))\n",
    "\n",
    "    k0 = list(tagDict.keys())[0]\n",
    "    tags = np.zeros((subjLength,len(tagDict[k0])))\n",
    "\n",
    "    for i,k in enumerate(keys):\n",
    "        sys.stdout.write(\"\\r[{}/{}]\".format(i,len(keys)))\n",
    "        metaList = []\n",
    "        for kOI in keysOI:\n",
    "            metaList.append(metaDict[kOI][str(i)])\n",
    "\n",
    "        try:\n",
    "            metaList.extend(bBoxes[k][\"Body\"])\n",
    "        except KeyError as e:\n",
    "            metaList.extend([0,0,0,0])\n",
    "\n",
    "        try:\n",
    "            metaList.extend(bBoxes[k][\"Liver\"])\n",
    "        except KeyError as e:\n",
    "            metaList.extend([0,0,0,0])\n",
    "\n",
    "        try:\n",
    "            metaList.extend(bBoxes[k][\"Lungs\"])\n",
    "        except KeyError as e:\n",
    "            metaList.extend([0,0,0,0])\n",
    "\n",
    "        try:\n",
    "            metaList.extend(bBoxes[k][\"Heart\"])\n",
    "        except KeyError as e:\n",
    "            metaList.extend([0,0,0,0])\n",
    "\n",
    "        charArr = np.char.find(fileList,k)\n",
    "        charIdx = np.argwhere(charArr == 0)[0,0]\n",
    "        \n",
    "        assert(type(charIdx) == np.int64)\n",
    "        errMeta = list(errFlat[charIdx,:])\n",
    "\n",
    "        metaList.extend(errMeta)\n",
    "\n",
    "        ownDataset[i,:] = np.array(metaList)\n",
    "        if k in tagDict.keys():\n",
    "            tags[i] = np.array(tagDict[k])\n",
    "\n",
    "    ownDataset = (ownDataset,tags)\n",
    "\n",
    "    print(\"\\n Meta Data for Subj0: {} \\n Tag for Subj0: {}\".format(ownDataset[0][0][:10],ownDataset[1][0]))\n",
    "\n",
    "# Create dataset (float only):\n",
    "else:\n",
    "    subjLength = len(keys)\n",
    "    dataLength = len(keysOI)*len(instTime)\n",
    "    print(\"Data Length: {}\\n\".format(dataLength))\n",
    "    bBoxesLength = 16\n",
    "    errLength = errFlat.shape[1]\n",
    "\n",
    "    ownDataset = np.zeros((subjLength,dataLength + bBoxesLength + errLength))\n",
    "\n",
    "    k0 = list(tagDict.keys())[0]\n",
    "    tags = np.zeros((subjLength,len(tagDict[k0])))\n",
    "\n",
    "    for i,k in enumerate(keys):\n",
    "        sys.stdout.write(\"\\r[{}/{}]\".format(i,len(keys)))\n",
    "        metaList = []\n",
    "        for kOI in keysOI:\n",
    "            for inst in instTime:\n",
    "                metaList.append(metaDict[k][inst][kOI])\n",
    "        try:\n",
    "            metaList.extend(bBoxes[k][\"Body\"])\n",
    "        except KeyError as e:\n",
    "            metaList.extend([0,0,0,0])\n",
    "\n",
    "        try:\n",
    "            metaList.extend(bBoxes[k][\"Liver\"])\n",
    "        except KeyError as e:\n",
    "            metaList.extend([0,0,0,0])\n",
    "\n",
    "        try:\n",
    "            metaList.extend(bBoxes[k][\"Lungs\"])\n",
    "        except KeyError as e:\n",
    "            metaList.extend([0,0,0,0])\n",
    "\n",
    "        try:\n",
    "            metaList.extend(bBoxes[k][\"Heart\"])\n",
    "        except KeyError as e:\n",
    "            metaList.extend([0,0,0,0])\n",
    "\n",
    "        charArr = np.char.find(fileList,k)\n",
    "        charIdx = np.argwhere(charArr == 0)[0,0]\n",
    "        \n",
    "        assert(type(charIdx) == np.int64)\n",
    "        errMeta = list(errFlat[charIdx,:])\n",
    "\n",
    "        metaList.extend(errMeta)\n",
    "\n",
    "        ownDataset[i,:] = np.array(metaList)\n",
    "        if k in tagDict.keys():\n",
    "            tags[i] = np.array(tagDict[k])\n",
    "\n",
    "    ownDataset = (ownDataset,tags)\n",
    "\n",
    "    print(\"\\n Meta Data for Subj0: {} \\n Tag for Subj0: {}\".format(ownDataset[0][0][:10],ownDataset[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Header Meta Data: 286 \nBounding Box Meta Data: 16 \nImage Recon Errors: 392 \n\n"
     ]
    }
   ],
   "source": [
    "print(\"Header Meta Data: {} \\nBounding Box Meta Data: {} \\nImage Recon Errors: {} \\n\".format(dataLength,bBoxesLength,errLength))"
   ]
  },
  {
   "source": [
    "# Train Random Forests:\n",
    "\n",
    "## All Data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "\n",
    "testSize = 0.5\n",
    "n_estimators = 100\n",
    "max_depth = 10\n",
    "tagNames = ['Artifacts', 'badsequence', 'Field_artefacts', 'highiron-lowt1', 'lookuptable-rip', 'm50pcfail', 'Other_Unlisted', 'pdff35', 'Rainbow', 'Segmentation_fail', 'Wrong_location', 'zeroct1']\n",
    "numAvgs = np.arange(0,20,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = ownDataset\n",
    "\n",
    "metricsDict = {}\n",
    "clfDict = {}\n",
    "\n",
    "topAUC = {}\n",
    "avgAUC = {}\n",
    "for name in tagNames:\n",
    "    topAUC[name] = 0.0\n",
    "    metricsDict[name] = {}\n",
    "    avgAUC[name] = []\n",
    "    clfDict[name] = {}\n",
    "\n",
    "cnt = 0\n",
    "for idx,name in enumerate(tagNames):\n",
    "\n",
    "    y = y0[:,idx]\n",
    "    X = x0[:,:]\n",
    "\n",
    "    rskf = RepeatedStratifiedKFold(random_state=42)\n",
    "\n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "        sys.stdout.write(\"\\r[{}/{}]\".format(cnt,5*10*len(tagNames)))\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth,verbose=False,n_jobs=-1)\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        probs = clf.predict_proba(X_test)\n",
    "\n",
    "        fpr,tpr,thresh = roc_curve(y_test,probs[:,1])\n",
    "        auc_score = roc_auc_score(y_test,probs[:,1])\n",
    "\n",
    "        avgAUC[name].append(auc_score)\n",
    "\n",
    "        if topAUC[name] < auc_score:\n",
    "            topAUC[name] = auc_score\n",
    "\n",
    "            clfDict[name][\"Classifier\"] = clf\n",
    "            clfDict[name][\"X_train\"] = X_train\n",
    "            clfDict[name][\"y_train\"] = y_train\n",
    "            clfDict[name][\"X_test\"] = X_test\n",
    "            clfDict[name][\"y_test\"] = y_test\n",
    "\n",
    "            metricsDict[name][\"AUC\"] = auc_score\n",
    "            metricsDict[name][\"FPR\"] = fpr\n",
    "            metricsDict[name][\"TPR\"] = tpr\n",
    "\n",
    "        cnt +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format for Seaborn\n",
    "\n",
    "modelsArr = []\n",
    "fprArr = []\n",
    "tprArr = []\n",
    "\n",
    "for name in tagNames:\n",
    "    auc_score = metricsDict[name][\"AUC\"]\n",
    "    fpr = metricsDict[name][\"FPR\"]\n",
    "    tpr = metricsDict[name][\"TPR\"]\n",
    "\n",
    "    event = [\"{}, AUC = {:.3f}\".format(name,auc_score)]*(fpr.shape[0])\n",
    "\n",
    "    modelsArr.extend(event)\n",
    "    fprArr.extend(fpr)\n",
    "    tprArr.extend(tpr)\n",
    "\n",
    "event = np.array(modelsArr)\n",
    "fpr = np.array(fprArr)\n",
    "tpr = np.array(tprArr)\n",
    "\n",
    "df = pandas.DataFrame({\"Model\":event,\"false positive rate\":fpr,\"true positive rate\":tpr})\n",
    "df2 = pandas.DataFrame(avgAUC)\n",
    "print(df2.describe())\n",
    "\n",
    "print(\"#\"*50)\n",
    "\n",
    "tempDict = {\"Name\":tagNames,\"Max AUC\":[metricsDict[name][\"AUC\"] for name in tagNames],\"Avg AUC\":[np.mean(avgAUC[name]) for name in tagNames]}\n",
    "\n",
    "df3 = pandas.DataFrame(tempDict)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves for each Class (One Vs Rest)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Everything\")\n",
    "sns.lineplot(x=[0,1],y=[0,1],linestyle=\"-.\",color='black')\n",
    "sns.lineplot(data=df,x=\"false positive rate\",y=\"true positive rate\",hue=\"Model\",style=\"Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictBox = {\"Class\":[],\"AUC\":[]}\n",
    "for k in avgAUC.keys():\n",
    "    for itm in avgAUC[k]:\n",
    "        dictBox[\"Class\"].append(k)\n",
    "        dictBox[\"AUC\"].append(itm)\n",
    "\n",
    "dfBox = pandas.DataFrame(dictBox)\n",
    "\n",
    "sns.boxplot(x=\"Class\",y=\"AUC\",data=dfBox)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Models\n",
    "saveDir = \"./models/Random Forests/All_Meta/\"\n",
    "\n",
    "if not os.path.isdir(saveDir):\n",
    "    os.mkdir(saveDir)\n",
    "\n",
    "for name in tagNames:\n",
    "    if not os.path.isdir(os.path.join(saveDir,name)):\n",
    "        os.mkdir(os.path.join(saveDir,name))\n",
    "    pickle.dump(clfDict[name], open(os.path.join(saveDir,name,\"classifier.sav\"),'wb'))\n",
    "\n",
    "df2.to_excel(os.path.join(saveDir,\"metrics.xlsx\"))\n",
    "df2.to_json(os.path.join(saveDir,\"metrics.json\"))\n",
    "\n",
    "df.to_excel(os.path.join(saveDir,\"roc_values.xlsx\"))\n",
    "df.to_json(os.path.join(saveDir,\"roc_values.json\"))"
   ]
  },
  {
   "source": [
    "## Meta + Bboxes:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = ownDataset\n",
    "\n",
    "metricsDict = {}\n",
    "clfDict = {}\n",
    "\n",
    "topAUC = {}\n",
    "avgAUC = {}\n",
    "for name in tagNames:\n",
    "    topAUC[name] = 0.0\n",
    "    metricsDict[name] = {}\n",
    "    avgAUC[name] = []\n",
    "    clfDict[name] = {}\n",
    "\n",
    "cnt = 0\n",
    "for idx,name in enumerate(tagNames):\n",
    "\n",
    "    y = y0[:,idx]\n",
    "    X = x0[:,:-errLength]\n",
    "\n",
    "    rskf = RepeatedStratifiedKFold(random_state=42)\n",
    "\n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "        sys.stdout.write(\"\\r[{}/{}]\".format(cnt,5*10*len(tagNames)))\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth,verbose=False,n_jobs=-1)\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        probs = clf.predict_proba(X_test)\n",
    "\n",
    "        fpr,tpr,thresh = roc_curve(y_test,probs[:,1])\n",
    "        auc_score = roc_auc_score(y_test,probs[:,1])\n",
    "\n",
    "        avgAUC[name].append(auc_score)\n",
    "\n",
    "        if topAUC[name] < auc_score:\n",
    "            topAUC[name] = auc_score\n",
    "\n",
    "            clfDict[name][\"Classifier\"] = clf\n",
    "            clfDict[name][\"X_train\"] = X_train\n",
    "            clfDict[name][\"y_train\"] = y_train\n",
    "            clfDict[name][\"X_test\"] = X_test\n",
    "            clfDict[name][\"y_test\"] = y_test\n",
    "\n",
    "            metricsDict[name][\"AUC\"] = auc_score\n",
    "            metricsDict[name][\"FPR\"] = fpr\n",
    "            metricsDict[name][\"TPR\"] = tpr\n",
    "\n",
    "        cnt +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format for Seaborn\n",
    "\n",
    "modelsArr = []\n",
    "fprArr = []\n",
    "tprArr = []\n",
    "\n",
    "for name in tagNames:\n",
    "    auc_score = metricsDict[name][\"AUC\"]\n",
    "    fpr = metricsDict[name][\"FPR\"]\n",
    "    tpr = metricsDict[name][\"TPR\"]\n",
    "\n",
    "    event = [\"{}, AUC = {:.3f}\".format(name,auc_score)]*(fpr.shape[0])\n",
    "\n",
    "    modelsArr.extend(event)\n",
    "    fprArr.extend(fpr)\n",
    "    tprArr.extend(tpr)\n",
    "\n",
    "event = np.array(modelsArr)\n",
    "fpr = np.array(fprArr)\n",
    "tpr = np.array(tprArr)\n",
    "\n",
    "df = pandas.DataFrame({\"Model\":event,\"false positive rate\":fpr,\"true positive rate\":tpr})\n",
    "df2 = pandas.DataFrame(avgAUC)\n",
    "print(df2.describe())\n",
    "\n",
    "print(\"#\"*50)\n",
    "\n",
    "tempDict = {\"Name\":tagNames,\"Max AUC\":[metricsDict[name][\"AUC\"] for name in tagNames],\"Avg AUC\":[np.mean(avgAUC[name]) for name in tagNames]}\n",
    "\n",
    "df3 = pandas.DataFrame(tempDict)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves for each Class (One Vs Rest)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Meta + Bounding Boxes\")\n",
    "sns.lineplot(x=[0,1],y=[0,1],linestyle=\"-.\",color='black')\n",
    "sns.lineplot(data=df,x=\"false positive rate\",y=\"true positive rate\",hue=\"Model\",style=\"Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictBox = {\"Class\":[],\"AUC\":[]}\n",
    "for k in avgAUC.keys():\n",
    "    for itm in avgAUC[k]:\n",
    "        dictBox[\"Class\"].append(k)\n",
    "        dictBox[\"AUC\"].append(itm)\n",
    "\n",
    "dfBox = pandas.DataFrame(dictBox)\n",
    "\n",
    "sns.boxplot(x=\"Class\",y=\"AUC\",data=dfBox)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Models\n",
    "saveDir = \"./models/Random Forests/Meta_BBoxes/\"\n",
    "\n",
    "if not os.path.isdir(saveDir):\n",
    "    os.mkdir(saveDir)\n",
    "\n",
    "for name in tagNames:\n",
    "    if not os.path.isdir(os.path.join(saveDir,name)):\n",
    "        os.mkdir(os.path.join(saveDir,name))\n",
    "    pickle.dump(clfDict[name], open(os.path.join(saveDir,name,\"classifier.sav\"),'wb'))\n",
    "\n",
    "df2.to_excel(os.path.join(saveDir,\"metrics.xlsx\"))\n",
    "df2.to_json(os.path.join(saveDir,\"metrics.json\"))\n",
    "\n",
    "df.to_excel(os.path.join(saveDir,\"roc_values.xlsx\"))\n",
    "df.to_json(os.path.join(saveDir,\"roc_values.json\"))"
   ]
  },
  {
   "source": [
    "## Meta Only:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = ownDataset\n",
    "\n",
    "metricsDict = {}\n",
    "clfDict = {}\n",
    "\n",
    "topAUC = {}\n",
    "avgAUC = {}\n",
    "for name in tagNames:\n",
    "    topAUC[name] = 0.0\n",
    "    metricsDict[name] = {}\n",
    "    avgAUC[name] = []\n",
    "    clfDict[name] = {}\n",
    "\n",
    "cnt = 0\n",
    "for idx,name in enumerate(tagNames):\n",
    "\n",
    "    y = y0[:,idx]\n",
    "    X = x0[:,:-(bBoxesLength+errLength)]\n",
    "\n",
    "    rskf = RepeatedStratifiedKFold(random_state=42)\n",
    "\n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "        sys.stdout.write(\"\\r[{}/{}]\".format(cnt,5*10*len(tagNames)))\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth,verbose=False,n_jobs=-1)\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        probs = clf.predict_proba(X_test)\n",
    "\n",
    "        fpr,tpr,thresh = roc_curve(y_test,probs[:,1])\n",
    "        auc_score = roc_auc_score(y_test,probs[:,1])\n",
    "\n",
    "        avgAUC[name].append(auc_score)\n",
    "\n",
    "        if topAUC[name] < auc_score:\n",
    "            topAUC[name] = auc_score\n",
    "\n",
    "            clfDict[name][\"Classifier\"] = clf\n",
    "            clfDict[name][\"X_train\"] = X_train\n",
    "            clfDict[name][\"y_train\"] = y_train\n",
    "            clfDict[name][\"X_test\"] = X_test\n",
    "            clfDict[name][\"y_test\"] = y_test\n",
    "\n",
    "            metricsDict[name][\"AUC\"] = auc_score\n",
    "            metricsDict[name][\"FPR\"] = fpr\n",
    "            metricsDict[name][\"TPR\"] = tpr\n",
    "\n",
    "        cnt +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format for Seaborn\n",
    "\n",
    "modelsArr = []\n",
    "fprArr = []\n",
    "tprArr = []\n",
    "\n",
    "for name in tagNames:\n",
    "    auc_score = metricsDict[name][\"AUC\"]\n",
    "    fpr = metricsDict[name][\"FPR\"]\n",
    "    tpr = metricsDict[name][\"TPR\"]\n",
    "\n",
    "    event = [\"{}, AUC = {:.3f}\".format(name,auc_score)]*(fpr.shape[0])\n",
    "\n",
    "    modelsArr.extend(event)\n",
    "    fprArr.extend(fpr)\n",
    "    tprArr.extend(tpr)\n",
    "\n",
    "event = np.array(modelsArr)\n",
    "fpr = np.array(fprArr)\n",
    "tpr = np.array(tprArr)\n",
    "\n",
    "df = pandas.DataFrame({\"Model\":event,\"false positive rate\":fpr,\"true positive rate\":tpr})\n",
    "df2 = pandas.DataFrame(avgAUC)\n",
    "print(df2.describe())\n",
    "\n",
    "print(\"#\"*50)\n",
    "\n",
    "tempDict = {\"Name\":tagNames,\"Max AUC\":[metricsDict[name][\"AUC\"] for name in tagNames],\"Avg AUC\":[np.mean(avgAUC[name]) for name in tagNames]}\n",
    "\n",
    "df3 = pandas.DataFrame(tempDict)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves for each Class (One Vs Rest)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Meta Only\")\n",
    "sns.lineplot(x=[0,1],y=[0,1],linestyle=\"-.\",color='black')\n",
    "sns.lineplot(data=df,x=\"false positive rate\",y=\"true positive rate\",hue=\"Model\",style=\"Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictBox = {\"Class\":[],\"AUC\":[]}\n",
    "for k in avgAUC.keys():\n",
    "    for itm in avgAUC[k]:\n",
    "        dictBox[\"Class\"].append(k)\n",
    "        dictBox[\"AUC\"].append(itm)\n",
    "\n",
    "dfBox = pandas.DataFrame(dictBox)\n",
    "\n",
    "sns.boxplot(x=\"Class\",y=\"AUC\",data=dfBox)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Models\n",
    "saveDir = \"./models/Random Forests/Meta_Only/\"\n",
    "\n",
    "if not os.path.isdir(saveDir):\n",
    "    os.mkdir(saveDir)\n",
    "\n",
    "for name in tagNames:\n",
    "    if not os.path.isdir(os.path.join(saveDir,name)):\n",
    "        os.mkdir(os.path.join(saveDir,name))\n",
    "    pickle.dump(clfDict[name], open(os.path.join(saveDir,name,\"classifier.sav\"),'wb'))\n",
    "\n",
    "df2.to_excel(os.path.join(saveDir,\"metrics.xlsx\"))\n",
    "df2.to_json(os.path.join(saveDir,\"metrics.json\"))\n",
    "\n",
    "df.to_excel(os.path.join(saveDir,\"roc_values.xlsx\"))\n",
    "df.to_json(os.path.join(saveDir,\"roc_values.json\"))"
   ]
  },
  {
   "source": [
    "## Error Only: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = ownDataset\n",
    "\n",
    "metricsDict = {}\n",
    "clfDict = {}\n",
    "\n",
    "topAUC = {}\n",
    "avgAUC = {}\n",
    "for name in tagNames:\n",
    "    topAUC[name] = 0.0\n",
    "    metricsDict[name] = {}\n",
    "    avgAUC[name] = []\n",
    "    clfDict[name] = {}\n",
    "\n",
    "cnt = 0\n",
    "for idx,name in enumerate(tagNames):\n",
    "\n",
    "    y = y0[:,idx]\n",
    "    X = x0[:,-errLength:]\n",
    "\n",
    "    rskf = RepeatedStratifiedKFold(random_state=42)\n",
    "\n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "        sys.stdout.write(\"\\r[{}/{}]\".format(cnt,5*10*len(tagNames)))\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth,verbose=False,n_jobs=-1)\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        probs = clf.predict_proba(X_test)\n",
    "\n",
    "        fpr,tpr,thresh = roc_curve(y_test,probs[:,1])\n",
    "        auc_score = roc_auc_score(y_test,probs[:,1])\n",
    "\n",
    "        avgAUC[name].append(auc_score)\n",
    "\n",
    "        if topAUC[name] < auc_score:\n",
    "            topAUC[name] = auc_score\n",
    "\n",
    "            clfDict[name][\"Classifier\"] = clf\n",
    "            clfDict[name][\"X_train\"] = X_train\n",
    "            clfDict[name][\"y_train\"] = y_train\n",
    "            clfDict[name][\"X_test\"] = X_test\n",
    "            clfDict[name][\"y_test\"] = y_test\n",
    "\n",
    "            metricsDict[name][\"AUC\"] = auc_score\n",
    "            metricsDict[name][\"FPR\"] = fpr\n",
    "            metricsDict[name][\"TPR\"] = tpr\n",
    "\n",
    "        cnt +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format for Seaborn\n",
    "\n",
    "modelsArr = []\n",
    "fprArr = []\n",
    "tprArr = []\n",
    "\n",
    "for name in tagNames:\n",
    "    auc_score = metricsDict[name][\"AUC\"]\n",
    "    fpr = metricsDict[name][\"FPR\"]\n",
    "    tpr = metricsDict[name][\"TPR\"]\n",
    "\n",
    "    event = [\"{}, AUC = {:.3f}\".format(name,auc_score)]*(fpr.shape[0])\n",
    "\n",
    "    modelsArr.extend(event)\n",
    "    fprArr.extend(fpr)\n",
    "    tprArr.extend(tpr)\n",
    "\n",
    "event = np.array(modelsArr)\n",
    "fpr = np.array(fprArr)\n",
    "tpr = np.array(tprArr)\n",
    "\n",
    "df = pandas.DataFrame({\"Model\":event,\"false positive rate\":fpr,\"true positive rate\":tpr})\n",
    "df2 = pandas.DataFrame(avgAUC)\n",
    "print(df2.describe())\n",
    "\n",
    "print(\"#\"*50)\n",
    "\n",
    "tempDict = {\"Name\":tagNames,\"Max AUC\":[metricsDict[name][\"AUC\"] for name in tagNames],\"Avg AUC\":[np.mean(avgAUC[name]) for name in tagNames]}\n",
    "\n",
    "df3 = pandas.DataFrame(tempDict)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves for each Class (One Vs Rest)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Error Only\")\n",
    "sns.lineplot(x=[0,1],y=[0,1],linestyle=\"-.\",color='black')\n",
    "sns.lineplot(data=df,x=\"false positive rate\",y=\"true positive rate\",hue=\"Model\",style=\"Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictBox = {\"Class\":[],\"AUC\":[]}\n",
    "for k in avgAUC.keys():\n",
    "    for itm in avgAUC[k]:\n",
    "        dictBox[\"Class\"].append(k)\n",
    "        dictBox[\"AUC\"].append(itm)\n",
    "\n",
    "dfBox = pandas.DataFrame(dictBox)\n",
    "\n",
    "sns.boxplot(x=\"Class\",y=\"AUC\",data=dfBox)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Models\n",
    "saveDir = \"./models/Random Forests/Error_Only/\"\n",
    "\n",
    "if not os.path.isdir(saveDir):\n",
    "    os.mkdir(saveDir)\n",
    "\n",
    "for name in tagNames:\n",
    "    if not os.path.isdir(os.path.join(saveDir,name)):\n",
    "        os.mkdir(os.path.join(saveDir,name))\n",
    "    pickle.dump(clfDict[name], open(os.path.join(saveDir,name,\"classifier.sav\"),'wb'))\n",
    "\n",
    "df2.to_excel(os.path.join(saveDir,\"metrics.xlsx\"))\n",
    "df2.to_json(os.path.join(saveDir,\"metrics.json\"))\n",
    "\n",
    "df.to_excel(os.path.join(saveDir,\"roc_values.xlsx\"))\n",
    "df.to_json(os.path.join(saveDir,\"roc_values.json\"))"
   ]
  },
  {
   "source": [
    "## Error + BBoxes:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = ownDataset\n",
    "\n",
    "metricsDict = {}\n",
    "clfDict = {}\n",
    "\n",
    "topAUC = {}\n",
    "avgAUC = {}\n",
    "for name in tagNames:\n",
    "    topAUC[name] = 0.0\n",
    "    metricsDict[name] = {}\n",
    "    avgAUC[name] = []\n",
    "    clfDict[name] = {}\n",
    "\n",
    "cnt = 0\n",
    "for idx,name in enumerate(tagNames):\n",
    "\n",
    "    y = y0[:,idx]\n",
    "    X = x0[:,-(errLength+bBoxesLength):]\n",
    "\n",
    "    rskf = RepeatedStratifiedKFold(random_state=42)\n",
    "\n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "        sys.stdout.write(\"\\r[{}/{}]\".format(cnt,5*10*len(tagNames)))\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth,verbose=False,n_jobs=-1)\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        probs = clf.predict_proba(X_test)\n",
    "\n",
    "        fpr,tpr,thresh = roc_curve(y_test,probs[:,1])\n",
    "        auc_score = roc_auc_score(y_test,probs[:,1])\n",
    "\n",
    "        avgAUC[name].append(auc_score)\n",
    "\n",
    "        if topAUC[name] < auc_score:\n",
    "            topAUC[name] = auc_score\n",
    "\n",
    "            clfDict[name][\"Classifier\"] = clf\n",
    "            clfDict[name][\"X_train\"] = X_train\n",
    "            clfDict[name][\"y_train\"] = y_train\n",
    "            clfDict[name][\"X_test\"] = X_test\n",
    "            clfDict[name][\"y_test\"] = y_test\n",
    "\n",
    "            metricsDict[name][\"AUC\"] = auc_score\n",
    "            metricsDict[name][\"FPR\"] = fpr\n",
    "            metricsDict[name][\"TPR\"] = tpr\n",
    "\n",
    "        cnt +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format for Seaborn\n",
    "\n",
    "modelsArr = []\n",
    "fprArr = []\n",
    "tprArr = []\n",
    "\n",
    "for name in tagNames:\n",
    "    auc_score = metricsDict[name][\"AUC\"]\n",
    "    fpr = metricsDict[name][\"FPR\"]\n",
    "    tpr = metricsDict[name][\"TPR\"]\n",
    "\n",
    "    event = [\"{}, AUC = {:.3f}\".format(name,auc_score)]*(fpr.shape[0])\n",
    "\n",
    "    modelsArr.extend(event)\n",
    "    fprArr.extend(fpr)\n",
    "    tprArr.extend(tpr)\n",
    "\n",
    "event = np.array(modelsArr)\n",
    "fpr = np.array(fprArr)\n",
    "tpr = np.array(tprArr)\n",
    "\n",
    "df = pandas.DataFrame({\"Model\":event,\"false positive rate\":fpr,\"true positive rate\":tpr})\n",
    "df2 = pandas.DataFrame(avgAUC)\n",
    "print(df2.describe())\n",
    "\n",
    "print(\"#\"*50)\n",
    "\n",
    "tempDict = {\"Name\":tagNames,\"Max AUC\":[metricsDict[name][\"AUC\"] for name in tagNames],\"Avg AUC\":[np.mean(avgAUC[name]) for name in tagNames]}\n",
    "\n",
    "df3 = pandas.DataFrame(tempDict)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves for each Class (One Vs Rest)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Error + Bounding Boxes\")\n",
    "sns.lineplot(x=[0,1],y=[0,1],linestyle=\"-.\",color='black')\n",
    "sns.lineplot(data=df,x=\"false positive rate\",y=\"true positive rate\",hue=\"Model\",style=\"Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictBox = {\"Class\":[],\"AUC\":[]}\n",
    "for k in avgAUC.keys():\n",
    "    for itm in avgAUC[k]:\n",
    "        dictBox[\"Class\"].append(k)\n",
    "        dictBox[\"AUC\"].append(itm)\n",
    "\n",
    "dfBox = pandas.DataFrame(dictBox)\n",
    "\n",
    "sns.boxplot(x=\"Class\",y=\"AUC\",data=dfBox)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Models\n",
    "saveDir = \"./models/Random Forests/Error_BBoxes/\"\n",
    "\n",
    "if not os.path.isdir(saveDir):\n",
    "    os.mkdir(saveDir)\n",
    "\n",
    "for name in tagNames:\n",
    "    if not os.path.isdir(os.path.join(saveDir,name)):\n",
    "        os.mkdir(os.path.join(saveDir,name))\n",
    "    pickle.dump(clfDict[name], open(os.path.join(saveDir,name,\"classifier.sav\"),'wb'))\n",
    "\n",
    "df2.to_excel(os.path.join(saveDir,\"metrics.xlsx\"))\n",
    "df2.to_json(os.path.join(saveDir,\"metrics.json\"))\n",
    "\n",
    "df.to_excel(os.path.join(saveDir,\"roc_values.xlsx\"))\n",
    "df.to_json(os.path.join(saveDir,\"roc_values.json\"))"
   ]
  },
  {
   "source": [
    "# AUC Comparisons:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loadDir = \"./models/Random Forests/\"\n",
    "\n",
    "ignoreList = [\"Float\",\"Float_Categorical\"]\n",
    "rfList = [x for x in os.listdir(loadDir) if x not in ignoreList]\n",
    "\n",
    "fullDict = {}\n",
    "for fol in rfList:\n",
    "    fullDict[fol] = {}\n",
    "    with open(os.path.join(loadDir,fol,\"metrics.json\")) as f:\n",
    "        metrics = json.load(f)\n",
    "    for k1 in metrics.keys():\n",
    "        avgAUC = []\n",
    "        for k2 in metrics[k1].keys():\n",
    "            avgAUC.append(metrics[k1][k2])\n",
    "        fullDict[fol][k1] = np.mean(avgAUC)\n",
    "\n",
    "df = pd.DataFrame(fullDict)\n",
    "print(df)\n",
    "\n",
    "plt.figure()\n",
    "sns.lineplot(data=df,markers=True)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"AUC of ROC\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = ownDataset\n",
    "\n",
    "newY = np.zeros(y0.shape[0])\n",
    "for i in range(y0.shape[0]):\n",
    "    if np.sum(y0[i,:]) >= 1:\n",
    "        newY[i] = 1\n",
    "\n",
    "y0 = newY\n",
    "\n",
    "modelsArr = []\n",
    "fprArr = []\n",
    "tprArr = []\n",
    "clfDict = {}\n",
    "\n",
    "names = [\"Everything\",\"Meta+Bboxes\",\"Meta\",\"Error\"]\n",
    "features = [(0,-1),(0,-errFlat.shape[1]),(0,-(16+errFlat.shape[1])),(-errFlat.shape[1],-1)]\n",
    "\n",
    "for name,(m,n) in zip(names,features):\n",
    "    clf = RandomForestClassifier(n_estimators=100,max_depth=10,verbose=False,n_jobs=-1)\n",
    "\n",
    "    y = y0\n",
    "    if n == -1:\n",
    "        X = x0[:,m:]\n",
    "    else:\n",
    "        X = x0[:,m:n]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.4,random_state=42)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    probs = clf.predict_proba(X_test)\n",
    "\n",
    "    fpr,tpr,thresh = roc_curve(y_test,probs[:,1])\n",
    "    auc_score = roc_auc_score(y_test,probs[:,1])\n",
    "\n",
    "    event = [\"{}, AUC = {:.3f}\".format(name,auc_score)]*(fpr.shape[0])\n",
    "\n",
    "    clfDict[name] = clf\n",
    "\n",
    "    modelsArr.extend(event)\n",
    "    fprArr.extend(fpr)\n",
    "    tprArr.extend(tpr)\n",
    "\n",
    "event = np.array(modelsArr)\n",
    "fpr = np.array(fprArr)\n",
    "tpr = np.array(tprArr)\n",
    "\n",
    "df = pandas.DataFrame({\"Model\":event,\"false positive rate\":fpr,\"true positive rate\":tpr})\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Include_Exclude\")\n",
    "sns.lineplot(x=[0,1],y=[0,1],linestyle=\"-.\",color='black')\n",
    "sns.lineplot(data=df,x=\"false positive rate\",y=\"true positive rate\",hue=\"Model\",style=\"Model\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Feature Importance:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "featuresPlot = {}\n",
    "for name in tagNames:\n",
    "    featuresPlot[name] = []\n",
    "\n",
    "for idx,name in enumerate(tagNames):\n",
    "    print(\"#\"*50)\n",
    "    print(name)\n",
    "    print(\"#\"*50)\n",
    "\n",
    "    clf = clfDict[name]\n",
    "    instCnt = 0\n",
    "    featCnt = -1\n",
    "    for i,fImp in enumerate(clf.feature_importances_):\n",
    "        if i % 7 == 0:\n",
    "            instCnt = 0\n",
    "            featCnt += 1\n",
    "        if fImp > 0.005:\n",
    "            featuresPlot[name].append((keysOI[featCnt],instTime[instCnt]))\n",
    "            print(\"{},\\t {}, \\t\\t\\t {}\".format(keysOI[featCnt],instTime[instCnt],fImp))\n",
    "        instCnt += 1\n",
    "    print(\"#\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Segmentation_fail\"\n",
    "\n",
    "features = [x[0] for x in featuresPlot['Artifacts']]\n",
    "features = list(set(features))\n",
    "\n",
    "for topFeature in features:\n",
    "    metaList = []\n",
    "    instTimeList = []\n",
    "    tagListStr = []\n",
    "    for i,k in enumerate(metaDict.keys()):\n",
    "        for inst in instTime:\n",
    "            instTimeList.append(inst)\n",
    "            metaList.append(metaDict[k][inst][topFeature])\n",
    "            if k in tagDict.keys():\n",
    "                issues = tagDict[k]\n",
    "                if issues[idx] == 1:\n",
    "                    tagListStr.append(\"Exclude\")\n",
    "                else:\n",
    "                    tagListStr.append(\"Include\")\n",
    "            else:\n",
    "                tagListStr.append(\"Include\")\n",
    "\n",
    "    d = {topFeature:metaList,\"Instance\":instTimeList,\"Class\":tagListStr}\n",
    "    df = pandas.DataFrame(data=d)\n",
    "\n",
    "    sns.violinplot(x=\"Instance\",y=topFeature,hue=\"Class\",split=False,data=df)\n",
    "    plt.show()\n"
   ]
  }
 ]
}